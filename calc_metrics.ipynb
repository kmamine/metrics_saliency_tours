{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eff26bd-6f6d-4b7a-b213-0c391f1f2b36",
   "metadata": {},
   "source": [
    "# Saliency metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad40ffa7-3e12-471c-bd20-5e72a2d9eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "def generate_dummy(size=14,num_fixations=100,num_salience_points=200):\n",
    "\t# first generate dummy gt and salience map\n",
    "\tdiscrete_gt = np.zeros((size,size))\n",
    "\ts_map = np.zeros((size,size))\n",
    "\n",
    "\tfor i in range(0,num_fixations):\n",
    "\t\tdiscrete_gt[np.random.randint(size),np.random.randint(size)] = 1.0\n",
    "\n",
    "\tfor i in range(0,num_salience_points):\n",
    "\t\ts_map[np.random.randint(size),np.random.randint(size)] = 255*round(random.random(),1)\n",
    "\n",
    "\n",
    "\t# check if gt and s_map are same size\n",
    "\tassert discrete_gt.shape==s_map.shape, 'sizes of ground truth and salience map don\\'t match'\n",
    "\treturn s_map,discrete_gt\n",
    "\n",
    "\n",
    "def normalize_map(s_map):\n",
    "\t# normalize the salience map (as done in MIT code)\n",
    "\tnorm_s_map = (s_map - np.min(s_map))/((np.max(s_map)-np.min(s_map))*1.0)\n",
    "\treturn norm_s_map\n",
    "\n",
    "def discretize_gt(gt):\n",
    "\t# import warnings\n",
    "\t# warnings.warn('can improve the way GT is discretized')\n",
    "\treturn gt/255\n",
    "\n",
    "def auc_judd(s_map,gt):\n",
    "\t# ground truth is discrete, s_map is continous and normalized\n",
    "\tgt = discretize_gt(gt)\n",
    "\t# thresholds are calculated from the salience map, only at places where fixations are present\n",
    "\tthresholds = []\n",
    "\tfor i in range(0,gt.shape[0]):\n",
    "\t\tfor k in range(0,gt.shape[1]):\n",
    "\t\t\tif gt[i][k]>0:\n",
    "\t\t\t\tthresholds.append(s_map[i][k])\n",
    "\n",
    "\t\n",
    "\tnum_fixations = np.sum(gt)\n",
    "\t# num fixations is no. of salience map values at gt >0\n",
    "\n",
    "\n",
    "\tthresholds = sorted(set(thresholds))\n",
    "\t\n",
    "\t#fp_list = []\n",
    "\t#tp_list = []\n",
    "\tarea = []\n",
    "\tarea.append((0.0,0.0))\n",
    "\tfor thresh in thresholds:\n",
    "\t\t# in the salience map, keep only those pixels with values above threshold\n",
    "\t\ttemp = np.zeros(s_map.shape)\n",
    "\t\ttemp[s_map>=thresh] = 1.0\n",
    "\t\tassert np.max(gt)==1.0, 'something is wrong with ground truth..not discretized properly max value > 1.0'\n",
    "\t\tassert np.max(s_map)==1.0, 'something is wrong with salience map..not normalized properly max value > 1.0'\n",
    "\t\tnum_overlap = np.where(np.add(temp,gt)==2)[0].shape[0]\n",
    "\t\ttp = num_overlap/(num_fixations*1.0)\n",
    "\t\t\n",
    "\t\t# total number of pixels > threshold - number of pixels that overlap with gt / total number of non fixated pixels\n",
    "\t\t# this becomes nan when gt is full of fixations..this won't happen\n",
    "\t\tfp = (np.sum(temp) - num_overlap)/((np.shape(gt)[0] * np.shape(gt)[1]) - num_fixations)\n",
    "\t\t\n",
    "\t\tarea.append((round(tp,4),round(fp,4)))\n",
    "\t\t#tp_list.append(tp)\n",
    "\t\t#fp_list.append(fp)\n",
    "\n",
    "\t#tp_list.reverse()\n",
    "\t#fp_list.reverse()\n",
    "\tarea.append((1.0,1.0))\n",
    "\t#tp_list.append(1.0)\n",
    "\t#fp_list.append(1.0)\n",
    "\t#print tp_list\n",
    "\tarea.sort(key = lambda x:x[0])\n",
    "\ttp_list =  [x[0] for x in area]\n",
    "\tfp_list =  [x[1] for x in area]\n",
    "\treturn np.trapz(np.array(tp_list),np.array(fp_list))\n",
    "\n",
    "\n",
    "\n",
    "def nss(s_map,gt):\n",
    "\tgt = discretize_gt(gt)\n",
    "\ts_map_norm = (s_map - np.mean(s_map))/np.std(s_map)\n",
    "\n",
    "\tx,y = np.where(gt==1)\n",
    "\ttemp = []\n",
    "\tfor i in zip(x,y):\n",
    "\t\ttemp.append(s_map_norm[i[0],i[1]])\n",
    "\treturn np.mean(temp)\n",
    "\n",
    "\n",
    "def infogain(s_map,gt,baseline_map):\n",
    "\tgt = discretize_gt(gt)\n",
    "\t# assuming s_map and baseline_map are normalized\n",
    "\teps = 2.2204e-16\n",
    "\n",
    "\ts_map = s_map/(np.sum(s_map)*1.0)\n",
    "\tbaseline_map = baseline_map/(np.sum(baseline_map)*1.0)\n",
    "\n",
    "\t# for all places where gt=1, calculate info gain\n",
    "\ttemp = []\n",
    "\tx,y = np.where(gt==1)\n",
    "\tfor i in zip(x,y):\n",
    "\t\ttemp.append(np.log2(eps + s_map[i[0],i[1]]) - np.log2(eps + baseline_map[i[0],i[1]]))\n",
    "\n",
    "\treturn np.mean(temp)\n",
    "\n",
    "\n",
    "\n",
    "def similarity(s_map,gt):\n",
    "\t# here gt is not discretized nor normalized\n",
    "\ts_map = normalize_map(s_map)\n",
    "\tgt = normalize_map(gt)\n",
    "\ts_map = s_map/(np.sum(s_map)*1.0)\n",
    "\tgt = gt/(np.sum(gt)*1.0)\n",
    "\tx,y = np.where(gt>0)\n",
    "\tsim = 0.0\n",
    "\tfor i in zip(x,y):\n",
    "\t\tsim = sim + min(gt[i[0],i[1]],s_map[i[0],i[1]])\n",
    "\treturn sim\n",
    "\n",
    "\n",
    "def cc(s_map,gt):\n",
    "\ts_map_norm = (s_map - np.mean(s_map))/np.std(s_map)\n",
    "\tgt_norm = (gt - np.mean(gt))/np.std(gt)\n",
    "\ta = s_map_norm\n",
    "\tb= gt_norm\n",
    "\tr = (a*b).sum() / math.sqrt((a*a).sum() * (b*b).sum());\n",
    "\treturn r\n",
    "\n",
    "\n",
    "def kldiv(s_map,gt):\n",
    "\ts_map = s_map/(np.sum(s_map)*1.0)\n",
    "\tgt = gt/(np.sum(gt)*1.0)\n",
    "\teps = 2.2204e-16\n",
    "\treturn np.sum(gt * np.log(eps + gt/(s_map + eps)))\n",
    "\n",
    "\n",
    "def calc_metrics(pred_sal, pred_fix, gt_sal, gt_fix ):  \n",
    "    metrics = {\n",
    "        'KLDiv' : np.nan, \n",
    "        'CC' : np.nan,\n",
    "        'SIM' : np.nan, \n",
    "        'AuC' : np.nan, \n",
    "        'NSS' : np.nan, \n",
    "        'InfoGain' : np.nan\n",
    "    }\n",
    "    try : \n",
    "        metrics['KLDiv']  = kldiv(pred_sal,gt_sal)\n",
    "    except: \n",
    "        metrics['KLDiv']  = np.nan\n",
    "\n",
    "    try : \n",
    "        metrics['CC']  = cc(pred_sal,gt_sal)\n",
    "    except: \n",
    "        metrics['CC']  = np.nan\n",
    "\n",
    "    try : \n",
    "        metrics['AuC']  = auc_judd(pred_sal,gt_sal)\n",
    "    except: \n",
    "        metrics['AuC']  = np.nan\n",
    "\n",
    "\n",
    "    try : \n",
    "        metrics['SIM']  = similarity(pred_sal,gt_sal)\n",
    "    except: \n",
    "        metrics['SIM']  = np.nan\n",
    "\n",
    "    try : \n",
    "        metrics['NSS']  = nss(pred_sal,gt_sal)\n",
    "    except: \n",
    "        metrics['NSS']  = np.nan\n",
    "\n",
    "    try : \n",
    "        metrics['InfoGain']  = infogain(pred_sal,gt_sal)\n",
    "    except: \n",
    "        metrics['InfoGain']  = np.nan\n",
    "\n",
    "    \n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672fee7-eab1-4d3f-9659-195518249414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427bf65b4ccf4e039e34c44194bfc2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1_o2_civita.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923639/3457132532.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_TD_TSA = pd.concat([metrics_TD_TSA,metrics_row] , ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3_o6_three.jpeg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "salmap_folder = \"./salmaps/\" \n",
    "fixation_folder = \"./fix_maps/\"\n",
    "\n",
    "td_folder = \"TD\"\n",
    "tdex_folder = \"TDex\"\n",
    "tsa_folder = \"TSA\"\n",
    "\n",
    "stimuli_names = os.listdir(os.path.join(fixation_folder, norm_folder)) \n",
    "\n",
    "metrics_names = ['KLDiv','CC' , 'SIM','AuC','NSS', 'InfoGain'] \n",
    "\n",
    "metrics_TD_TSA = pd.DataFrame(columns = metrics_names)\n",
    "metrics_TDex_TSA = pd.DataFrame(columns = metrics_names)\n",
    "\n",
    "# metrics_TD_TSA = pd.concat([metrics ,  d],  ) \n",
    "# metrics.append(d)\n",
    "\n",
    "# Compare TSA <=> TD \n",
    "for stimulus_name  in tqdm(stimuli_names):\n",
    "    print(stimulus_name)\n",
    "    tsa_fix_map_p_f = os.path.join(fixation_folder,tsa_folder,stimulus_name)\n",
    "    tsa_sal_map_p_f = os.path.join(salmap_folder,tsa_folder,stimulus_name)\n",
    "    td_fix_map_p_f = os.path.join(fixation_folder,td_folder,stimulus_name)\n",
    "    td_sal_map_p_f = os.path.join(salmap_folder,td_folder,stimulus_name)\n",
    "\n",
    "    tsa_fix_map_p = os.path.join(tsa_fix_map_p_f, [ x for x  in  os.listdir(tsa_fix_map_p_f) if not (\"ipy\" in  x) ][0]) \n",
    "    tsa_sal_map_p = os.path.join(tsa_sal_map_p_f, [ x for x  in  os.listdir(tsa_sal_map_p_f) if not (\"ipy\" in  x)][0] )\n",
    "    td_fix_map_p = os.path.join(td_fix_map_p_f, [ x for x  in  os.listdir(td_fix_map_p_f)  if not (\"ipy\" in  x) ][0] )\n",
    "    td_sal_map_p = os.path.join(td_sal_map_p_f, [ x for x  in  os.listdir(td_sal_map_p_f) if not (\"ipy\" in  x)][0])\n",
    "\n",
    "    tsa_fix_map = cv2.imread( tsa_fix_map_p ,0)  \n",
    "    tsa_sal_map = cv2.imread(tsa_sal_map_p ,0)\n",
    "    td_fix_map = cv2.imread(td_fix_map_p ,0)\n",
    "    td_sal_map = cv2.imread( td_sal_map_p,0)\n",
    "\n",
    "    # print(tsa_fix_map.shape , tsa_sal_map.shape,  td_fix_map.shape,  td_sal_map.shape)\n",
    "    metrics_row = calc_metrics(tsa_sal_map, tsa_fix_map, td_fix_map,td_sal_map)  \n",
    "    metrics_row = pd.DataFrame([metrics_row])\n",
    "    metrics_TD_TSA = pd.concat([metrics_TD_TSA,metrics_row], ignore_index=True)  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "317a270b-0886-476a-87c7-a87f4237be9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e7c6b836a94763a162a2262e40b78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1_o2_civita.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923639/516314851.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_TDex_TSA = pd.concat([metrics_TDex_TSA,metrics_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3_o6_three.jpeg\n",
      "c4_o4_woman.jpeg\n",
      "sam_beauté_jpeg.jpeg\n",
      "c5_o5_field.jpeg\n",
      "c4_o5_ventimiglia.jpeg\n",
      "c2_o2_stora.jpeg\n",
      "c4_o3_persistance.jpeg\n",
      "c3_o5_antigraceful.jpeg\n",
      "c5_o4_sails.jpeg\n",
      "c4_o6_monde.jpeg\n",
      "connaissance_jpeg.jpeg\n",
      "c2_o1_lordship.jpeg\n",
      "c5_o2_based.jpeg\n",
      "c1_o6_embouchment.jpeg\n",
      "c2_o4_saint_brac.jpeg\n",
      "c1_o5_wounded.jpeg\n",
      "c3_o4_still.jpeg\n",
      "c2_o5_seascape.jpeg\n",
      "c1_o1_view.jpeg\n",
      "c2_o3_mother.jpeg\n",
      "c5_o3_chaos.jpeg\n",
      "sam_plaisir_jpeg.jpeg\n",
      "sam_éveil_jpeg.jpeg\n",
      "c5_o1_abstraction.jpeg\n",
      "c4_o2_elephant.jpeg\n",
      "c4_o1_brainchain.jpeg\n",
      "c1_o4_sha.jpeg\n",
      "c5_o6_variation.jpeg\n",
      "c3_o1_joueurs.jpeg\n",
      "c2_o6_conversation.jpeg\n",
      "c3_o3_lake.jpeg\n",
      "c3_o2_balcon.jpeg\n",
      "c1_o3_portrait.jpeg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# metrics_TD_TSA = pd.concat([metrics ,  d],  ) \n",
    "# metrics.append(d)\n",
    "\n",
    "# Compare TSA <=> TDex \n",
    "for stimulus_name  in tqdm(stimuli_names):\n",
    "    print(stimulus_name)\n",
    "    td_fix_map_p_f = os.path.join(fixation_folder,td_folder,stimulus_name)\n",
    "    td_sal_map_p_f = os.path.join(salmap_folder,td_folder,stimulus_name)\n",
    "    tdex_fix_map_p_f = os.path.join(fixation_folder,tdex_folder,stimulus_name)\n",
    "    tdex_sal_map_p_f = os.path.join(salmap_folder,tdex_folder,stimulus_name)\n",
    "\n",
    "    td_fix_map_p = os.path.join(td_fix_map_p_f, [ x for x  in  os.listdir(td_fix_map_p_f) if not (\"ipy\" in  x) ][0]) \n",
    "    td_sal_map_p = os.path.join(td_sal_map_p_f, [ x for x  in  os.listdir(td_sal_map_p_f) if not (\"ipy\" in  x)][0] )\n",
    "    tdex_fix_map_p = os.path.join(tdex_fix_map_p_f, [ x for x  in  os.listdir(tdex_fix_map_p_f)  if not (\"ipy\" in  x) ][0] )\n",
    "    tdex_sal_map_p = os.path.join(tdex_sal_map_p_f, [ x for x  in  os.listdir(tdex_sal_map_p_f) if not (\"ipy\" in  x)][0])\n",
    "\n",
    "    td_fix_map = cv2.imread( td_fix_map_p ,0)  \n",
    "    td_sal_map = cv2.imread(td_sal_map_p ,0)\n",
    "    tdex_fix_map = cv2.imread(tdex_fix_map_p ,0)\n",
    "    tdex_sal_map = cv2.imread( tdex_sal_map_p,0)\n",
    "\n",
    "    # print(tsa_fix_map.shape , tsa_sal_map.shape,  td_fix_map.shape,  td_sal_map.shape)\n",
    "    metrics_row = calc_metrics(td_sal_map, td_fix_map, tdex_fix_map, tdex_sal_map)  \n",
    "    metrics_row = pd.DataFrame([metrics_row])\n",
    "    metrics_TDex_TSA = pd.concat([metrics_TDex_TSA,metrics_row], ignore_index=True)  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40230484-1f0c-43e8-979d-e86187c69513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b519323e57334bceac188f95046a5e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1_o2_civita.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923639/2520252913.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_TD_TDex = pd.concat([metrics_TD_TDex,metrics_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3_o6_three.jpeg\n",
      "c4_o4_woman.jpeg\n",
      "sam_beauté_jpeg.jpeg\n",
      "c5_o5_field.jpeg\n",
      "c4_o5_ventimiglia.jpeg\n",
      "c2_o2_stora.jpeg\n",
      "c4_o3_persistance.jpeg\n",
      "c3_o5_antigraceful.jpeg\n",
      "c5_o4_sails.jpeg\n",
      "c4_o6_monde.jpeg\n",
      "connaissance_jpeg.jpeg\n",
      "c2_o1_lordship.jpeg\n",
      "c5_o2_based.jpeg\n",
      "c1_o6_embouchment.jpeg\n",
      "c2_o4_saint_brac.jpeg\n",
      "c1_o5_wounded.jpeg\n",
      "c3_o4_still.jpeg\n",
      "c2_o5_seascape.jpeg\n",
      "c1_o1_view.jpeg\n",
      "c2_o3_mother.jpeg\n",
      "c5_o3_chaos.jpeg\n",
      "sam_plaisir_jpeg.jpeg\n",
      "sam_éveil_jpeg.jpeg\n",
      "c5_o1_abstraction.jpeg\n",
      "c4_o2_elephant.jpeg\n",
      "c4_o1_brainchain.jpeg\n",
      "c1_o4_sha.jpeg\n",
      "c5_o6_variation.jpeg\n",
      "c3_o1_joueurs.jpeg\n",
      "c2_o6_conversation.jpeg\n",
      "c3_o3_lake.jpeg\n",
      "c3_o2_balcon.jpeg\n",
      "c1_o3_portrait.jpeg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# metrics_TD_TSA = pd.concat([metrics ,  d],  ) \n",
    "# metrics.append(d)\n",
    "metrics_TD_TDex = pd.DataFrame(columns = metrics_names)\n",
    "\n",
    "# Compare TD <=> TDex \n",
    "for stimulus_name  in tqdm(stimuli_names):\n",
    "    print(stimulus_name)\n",
    "    td_fix_map_p_f = os.path.join(fixation_folder,td_folder,stimulus_name)\n",
    "    td_sal_map_p_f = os.path.join(salmap_folder,td_folder,stimulus_name)\n",
    "    tdex_fix_map_p_f = os.path.join(fixation_folder,tdex_folder,stimulus_name)\n",
    "    tdex_sal_map_p_f = os.path.join(salmap_folder,tdex_folder,stimulus_name)\n",
    "\n",
    "    td_fix_map_p = os.path.join(td_fix_map_p_f, [ x for x  in  os.listdir(td_fix_map_p_f) if not (\"ipy\" in  x) ][0]) \n",
    "    td_sal_map_p = os.path.join(td_sal_map_p_f, [ x for x  in  os.listdir(td_sal_map_p_f) if not (\"ipy\" in  x)][0] )\n",
    "    tdex_fix_map_p = os.path.join(tdex_fix_map_p_f, [ x for x  in  os.listdir(tdex_fix_map_p_f)  if not (\"ipy\" in  x) ][0] )\n",
    "    tdex_sal_map_p = os.path.join(tdex_sal_map_p_f, [ x for x  in  os.listdir(tdex_sal_map_p_f) if not (\"ipy\" in  x)][0])\n",
    "\n",
    "    td_fix_map = cv2.imread( td_fix_map_p ,0)  \n",
    "    td_sal_map = cv2.imread(td_sal_map_p ,0)\n",
    "    tdex_fix_map = cv2.imread(tdex_fix_map_p ,0)\n",
    "    tdex_sal_map = cv2.imread( tdex_sal_map_p,0)\n",
    "\n",
    "    # print(tsa_fix_map.shape , tsa_sal_map.shape,  td_fix_map.shape,  td_sal_map.shape)\n",
    "    metrics_row = calc_metrics(td_sal_map, td_fix_map, tdex_fix_map,tdex_sal_map)  \n",
    "    metrics_row = pd.DataFrame([metrics_row])\n",
    "    metrics_TD_TDex = pd.concat([metrics_TD_TDex,metrics_row], ignore_index=True)  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4505422b-ea2f-4183-971a-00b3bbc3f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_TD_TSA.to_pickle('metrics_TD_TSA.pickle')\n",
    "metrics_TDex_TSA.to_pickle('metrics_TDex_TSA.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "180eb9e7-de98-48b5-9962-8c5ce377b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_TD_TDex.to_pickle('metrics_TD_TDex.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34a19b55-10a6-4220-9678-e2326ae402e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KLDiv</th>\n",
       "      <th>CC</th>\n",
       "      <th>SIM</th>\n",
       "      <th>AuC</th>\n",
       "      <th>NSS</th>\n",
       "      <th>InfoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.833709</td>\n",
       "      <td>0.063115</td>\n",
       "      <td>0.034614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.155963</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.882492</td>\n",
       "      <td>0.076915</td>\n",
       "      <td>0.056674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008474</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.671415</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.133326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.995078</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.105175</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.017914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.176547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.744775</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.802978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.768912</td>\n",
       "      <td>0.274943</td>\n",
       "      <td>0.195901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.419940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           KLDiv         CC        SIM  AuC        NSS  InfoGain\n",
       "count  34.000000  34.000000  34.000000  0.0  34.000000       0.0\n",
       "mean   20.833709   0.063115   0.034614  NaN   1.155963       NaN\n",
       "std     5.882492   0.076915   0.056674  NaN   1.008474       NaN\n",
       "min    10.671415  -0.002314   0.000000  NaN  -0.133326       NaN\n",
       "25%    16.995078   0.001259   0.000547  NaN   0.104975       NaN\n",
       "50%    20.105175   0.039843   0.017914  NaN   1.176547       NaN\n",
       "75%    26.744775   0.079917   0.029524  NaN   1.802978       NaN\n",
       "max    29.768912   0.274943   0.195901  NaN   3.419940       NaN"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_TD_TDex.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b592516-d560-456b-976a-905db49519a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KLDiv</th>\n",
       "      <th>CC</th>\n",
       "      <th>SIM</th>\n",
       "      <th>AuC</th>\n",
       "      <th>NSS</th>\n",
       "      <th>InfoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.814230</td>\n",
       "      <td>0.073468</td>\n",
       "      <td>0.032021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.515937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.678878</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.028891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.249779</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.516826</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.445249</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.977617</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.089103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.511765</td>\n",
       "      <td>0.122984</td>\n",
       "      <td>0.057060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.567749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.960415</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.093913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.140181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           KLDiv         CC        SIM  AuC        NSS  InfoGain\n",
       "count  34.000000  34.000000  34.000000  0.0  34.000000       0.0\n",
       "mean   19.814230   0.073468   0.032021  NaN   1.515937       NaN\n",
       "std     5.678878   0.069006   0.028891  NaN   1.249779       NaN\n",
       "min     6.516826  -0.000009   0.001391  NaN  -0.000251       NaN\n",
       "25%    17.445249   0.018431   0.008856  NaN   0.494445       NaN\n",
       "50%    20.977617   0.046884   0.023689  NaN   1.089103       NaN\n",
       "75%    24.511765   0.122984   0.057060  NaN   2.567749       NaN\n",
       "max    26.960415   0.213904   0.093913  NaN   4.140181       NaN"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_TD_TSA.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8caea5b-364e-46af-93fa-11d451c75d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KLDiv</th>\n",
       "      <th>CC</th>\n",
       "      <th>SIM</th>\n",
       "      <th>AuC</th>\n",
       "      <th>NSS</th>\n",
       "      <th>InfoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.245821</td>\n",
       "      <td>0.056740</td>\n",
       "      <td>0.030373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.077564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.547997</td>\n",
       "      <td>0.080360</td>\n",
       "      <td>0.051394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.740121</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.143832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.811432</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199663</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.300644</td>\n",
       "      <td>0.025695</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.264902</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.640353</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.661647</td>\n",
       "      <td>0.320258</td>\n",
       "      <td>0.192717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.075273</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           KLDiv         CC        SIM  AuC        NSS  InfoGain\n",
       "count  34.000000  34.000000  34.000000  0.0  34.000000       0.0\n",
       "mean   22.245821   0.056740   0.030373  NaN   1.077564       NaN\n",
       "std     6.547997   0.080360   0.051394  NaN   1.111975       NaN\n",
       "min     5.740121  -0.001891   0.000000  NaN  -0.143832       NaN\n",
       "25%    20.811432   0.004111   0.001368  NaN   0.199663       NaN\n",
       "50%    22.300644   0.025695   0.006501  NaN   0.903298       NaN\n",
       "75%    27.264902   0.065080   0.026573  NaN   1.640353       NaN\n",
       "max    31.661647   0.320258   0.192717  NaN   4.075273       NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_TDex_TSA.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2da32a36-49e7-4bb6-84be-d872435b85a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLDiv       22.245821\n",
       "CC           0.056740\n",
       "SIM          0.030373\n",
       "AuC               NaN\n",
       "NSS          1.077564\n",
       "InfoGain          NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_TDex_TSA.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60bbdba2-656e-4ce2-8626-8e4e52bf97b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLDiv       19.814230\n",
       "CC           0.073468\n",
       "SIM          0.032021\n",
       "AuC               NaN\n",
       "NSS          1.515937\n",
       "InfoGain          NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_TD_TSA.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab622682-13f4-48bf-b3f9-fe895765b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('exp-et/data_organized/TDex/c1_o2_civita.jpeg/BEAT681_block2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66326d-fa4a-4685-9451-0e7cf93d3efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c90f52d5-7a23-4fd7-8de3-ff43a10517b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n",
      "2  5  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an initial DataFrame\n",
    "data = {\n",
    "    'A': [1, 2],\n",
    "    'B': [3, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a dictionary to add as a new row\n",
    "new_row = {'A': 5, 'B': 6}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "# Concatenate the new row DataFrame with the original DataFrame\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fe39a-d7b0-40fd-b2d6-0a0ecbcedf37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b319dd-ae15-453a-a435-d6f53593a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923639/509843620.py:32: UserWarning: can improve the way GT is discretized\n",
      "  warnings.warn('can improve the way GT is discretized')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KLDiv': np.float64(20.938411147541828),\n",
       " 'CC': np.float64(0.04203653084922859),\n",
       " 'SIM': np.float64(0.05702712726587408),\n",
       " 'AuC': nan,\n",
       " 'NSS': np.float64(-0.10469449755763655),\n",
       " 'InfoGain': nan}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gt_fix_map_p = \"./fix_maps/TD/c1_o1_view.jpeg/ANMT322_bloc1_fixation_map.png\"\n",
    "gt_sal_map_p = \"./salmaps/TD/c1_o1_view.jpeg/ANMT322_bloc1_saliency_map.png\"\n",
    "\n",
    "pred_fix_p = \"./fix_maps/TSA/c1_o1_view.jpeg/QUPP719_bloc1_fixation_map.png\"\n",
    "pred_sal_p = \"./salmaps/TSA/c1_o1_view.jpeg/QUPP719_bloc1_saliency_map.png\"\n",
    "\n",
    "\n",
    "# this is just the name its not actually discretised (binary)\n",
    "gt_sal = cv2.imread(gt_sal_map_p,0)\n",
    "gt_fix = cv2.imread(gt_fix_map_p,0)\n",
    "\n",
    "\n",
    "\n",
    "s_map = cv2.imread(pred_sal_p,0)\n",
    "s_map_norm = normalize_map(s_map)\n",
    "\n",
    "\n",
    "calc_metrics(s_map, None, gt_sal, gt_fix) \n",
    "\n",
    "# auc_judd_score = auc_judd(s_map_norm,gt_fix)\n",
    "# print('auc judd :', auc_judd_score)\n",
    "# # auc_borji_score = auc_borji(s_map_norm,gt_fix)\n",
    "# # print('auc borji :', auc_borji_score)\n",
    "# # auc_shuff_score = auc_shuff(s_map_norm,gt,gt)\n",
    "# # print 'auc shuffled :', auc_shuff_score\n",
    "\n",
    "# nss_score = nss(s_map,gt_fix)\n",
    "# print('nss :', nss_score)\n",
    "# # infogain_score = infogain(s_map_norm,gt,gt)\n",
    "# # print 'info gain :', infogain_score\n",
    "\n",
    "\n",
    "\n",
    "# #continous gts\n",
    "# sim_score = similarity(s_map,gt_sal)\n",
    "# print('sim score :', sim_score)\n",
    "# cc_score = cc(s_map,gt_sal)\n",
    "# print('cc score :',cc_score)\n",
    "# kldiv_score = kldiv(s_map,gt_sal)\n",
    "# print('kldiv score :',kldiv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46eced3c-9677-4957-a10e-74db74e910d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c1_o2_civita.jpeg',\n",
       " 'c3_o6_three.jpeg',\n",
       " 'c4_o4_woman.jpeg',\n",
       " 'sam_beauté_jpeg.jpeg',\n",
       " 'c5_o5_field.jpeg',\n",
       " 'c4_o5_ventimiglia.jpeg',\n",
       " 'c2_o2_stora.jpeg',\n",
       " 'c4_o3_persistance.jpeg',\n",
       " 'c3_o5_antigraceful.jpeg',\n",
       " 'c5_o4_sails.jpeg',\n",
       " 'c4_o6_monde.jpeg',\n",
       " 'connaissance_jpeg.jpeg',\n",
       " 'c2_o1_lordship.jpeg',\n",
       " 'c5_o2_based.jpeg',\n",
       " 'c1_o6_embouchment.jpeg',\n",
       " 'c2_o4_saint_brac.jpeg',\n",
       " 'c1_o5_wounded.jpeg',\n",
       " 'c3_o4_still.jpeg',\n",
       " 'c2_o5_seascape.jpeg',\n",
       " 'c1_o1_view.jpeg',\n",
       " 'c2_o3_mother.jpeg',\n",
       " 'c5_o3_chaos.jpeg',\n",
       " 'sam_plaisir_jpeg.jpeg',\n",
       " 'sam_éveil_jpeg.jpeg',\n",
       " 'c5_o1_abstraction.jpeg',\n",
       " 'c4_o2_elephant.jpeg',\n",
       " 'c4_o1_brainchain.jpeg',\n",
       " 'c1_o4_sha.jpeg',\n",
       " 'c5_o6_variation.jpeg',\n",
       " 'c3_o1_joueurs.jpeg',\n",
       " 'c2_o6_conversation.jpeg',\n",
       " 'c3_o3_lake.jpeg',\n",
       " 'c3_o2_balcon.jpeg',\n",
       " 'c1_o3_portrait.jpeg']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimuli "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision_kma",
   "language": "python",
   "name": "vision_kma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
